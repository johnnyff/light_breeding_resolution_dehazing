{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnnyff/light_breeding_resolution_dehazing_by_HARDGAN/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZfc-6El80g8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A3U_vDpPDfI"
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFJ-UOqKLAdj"
      },
      "source": [
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "from random import randrange\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "import torchvision.transforms as tfs\n",
        "from torchvision.transforms import functional as FF\n",
        "import random\n",
        "from glob import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "from torchvision.models import vgg16\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torch.nn import init\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzeJGm9AT3Xf"
      },
      "source": [
        "\n",
        "learning_rate = 1e-3\n",
        "crop_size = [240, 240]\n",
        "train_phrase = 10\n",
        "train_batch_size = 6\n",
        "network_height = 3\n",
        "network_width = 6\n",
        "num_dense_layer = 4\n",
        "growth_rate = 16\n",
        "lambda_loss = 0.04\n",
        "category = 'lg'\n",
        "\n",
        "print('--- Hyper-parameters for training ---')\n",
        "print('learning_rate: {}\\ncrop_size: {}\\ntrain_batch_size: {}\\nnetwork_height: {}\\nnetwork_width: {}\\n'\n",
        "      'num_dense_layer: {}\\ngrowth_rate: {}\\nlambda_loss: {}\\ncategory: {}'.format(learning_rate, crop_size,\n",
        "      train_batch_size, network_height, network_width, num_dense_layer, growth_rate, lambda_loss, category))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfFmIxcZZZHY"
      },
      "source": [
        "\n",
        "device_ids = [Id for Id in range(torch.cuda.device_count())]\n",
        "print(device_ids)\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "writer = SummaryWriter()\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQiZo56pc_4P"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        init.xavier_uniform(m.weight)\n",
        "        m.weight.data.normal_(0, 0.02)\n",
        "        m.bias.data.zero_()\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.xavier_uniform(m.weight)\n",
        "        m.weight.data.normal_(0, 0.02)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjWpR_EtaABY"
      },
      "source": [
        "#Phrase 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-XLk-abPvaW"
      },
      "source": [
        "\n",
        "# --- Build dense --- #\n",
        "class MakeDense(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate, kernel_size=3, dilation = 1):\n",
        "        super(MakeDense, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, growth_rate, kernel_size=kernel_size, padding=dilation, dilation=dilation)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv(x))\n",
        "        out = torch.cat((x, out), 1)\n",
        "        return out\n",
        "\n",
        "class AdaIn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AdaIn, self).__init__()\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x, mean_style, std_style):\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        feature = x.view(B, C, -1)\n",
        "\n",
        "        #print (mean_feat.shape, std_feat.shape, mean_style.shape, std_style.shape)\n",
        "        std_style = std_style.view(B, C, 1)\n",
        "        mean_style = mean_style.view(B, C, 1)\n",
        "        adain = std_style * (feature) + mean_style\n",
        "\n",
        "        adain = adain.view(B, C, H, W)\n",
        "        return adain\n",
        "\n",
        "class CALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(CALayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.ca = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 4, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 4, channel, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.ca(y)\n",
        "        return x * y\n",
        "\n",
        "class PALayer(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(PALayer, self).__init__()\n",
        "        self.pa = nn.Sequential(\n",
        "                nn.Conv2d(channel, channel // 4, 1, padding=0, bias=True),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(channel // 4, 1, 1, padding=0, bias=True),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        y = self.pa(x)\n",
        "        return x * y\n",
        "\n",
        "class ApplyNoise(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.zeros(channels))\n",
        "\n",
        "    def forward(self, x, noise):\n",
        "        if noise is None:\n",
        "            noise = torch.randn(x.size(0), 1, x.size(2), x.size(3), device=x.device, dtype=x.dtype)\n",
        "        return x + self.weight.view(1, -1, 1, 1) * noise.to(x.device)\n",
        "\n",
        "# --- Build the Residual Dense Block --- #\n",
        "class RDB(nn.Module):\n",
        "    def __init__(self, in_channels, num_dense_layer, growth_rate, dilations = [1, 1, 1, 1]):\n",
        "        \"\"\"\n",
        "\n",
        "        :param in_channels: input channel size\n",
        "        :param num_dense_layer: the number of RDB layers\n",
        "        :param growth_rate: growth_rate\n",
        "        \"\"\"\n",
        "        super(RDB, self).__init__()\n",
        "        _in_channels = in_channels\n",
        "        modules = []\n",
        "        for i in range(num_dense_layer):\n",
        "            modules.append(MakeDense(_in_channels, growth_rate, dilation = dilations[i]))\n",
        "            _in_channels += growth_rate\n",
        "        self.residual_dense_layers = nn.Sequential(*modules)\n",
        "\n",
        "        self.conv_1x1_a = nn.Conv2d(_in_channels, in_channels, kernel_size=1, padding=0)\n",
        "\n",
        "\n",
        "        _in_channels_no_style = in_channels\n",
        "        no_style_modules = []\n",
        "        for i in range(num_dense_layer):\n",
        "            no_style_modules.append(MakeDense(_in_channels_no_style, growth_rate))\n",
        "            _in_channels_no_style += growth_rate\n",
        "\n",
        "        self.residual_dense_layers_no_style = nn.Sequential(*no_style_modules)\n",
        "        self.conv_1x1_b = nn.Conv2d(_in_channels_no_style, in_channels, kernel_size=1, padding=0)\n",
        "\n",
        "        self.norm = nn.InstanceNorm2d(in_channels)\n",
        "        self.norm2 = nn.InstanceNorm2d(in_channels)\n",
        "        self.adaIn = AdaIn()\n",
        "\n",
        "        self.global_feat = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.style = nn.Linear(in_channels // 2, in_channels * 2)\n",
        "        self.conv_1x1_style = nn.Conv2d(in_channels, in_channels // 2, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv_gamma = nn.Conv2d(in_channels // 2, in_channels, kernel_size=3, padding=1)\n",
        "        self.conv_beta = nn.Conv2d(in_channels // 2, in_channels, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv_att = nn.Conv2d(in_channels, 1, kernel_size=3, padding=1)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        self.conv_1x1_final = nn.Conv2d(in_channels * 2, in_channels, kernel_size=1, padding=0)\n",
        "\n",
        "        self.coefficient = nn.Parameter(torch.Tensor(np.ones((1, 2))), requires_grad=True)\n",
        "        self.ca = CALayer(in_channels)\n",
        "        self.pool = nn.AvgPool2d((7, 7), stride=(1, 1), padding=(3, 3))\n",
        "\n",
        "        #self.noise = ApplyNoise(in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # residual\n",
        "        bottle_feat = self.residual_dense_layers(x)\n",
        "        out = self.conv_1x1_a(bottle_feat)\n",
        "        out = out + x\n",
        "\n",
        "        # base residual， self-guieded learn mean，std，gamma，and beta\n",
        "        style_feat_1 = F.relu(self.conv_1x1_style(out))\n",
        "        style_feat = self.global_feat(style_feat_1)\n",
        "        style_feat = torch.flatten(style_feat, start_dim = 1)\n",
        "        style_feat = self.style(style_feat)\n",
        "        # mean, std\n",
        "        style_mean = style_feat[:, :self.in_channels]\n",
        "        style_std = style_feat[:, self.in_channels:]\n",
        "\n",
        "        gamma = self.conv_gamma(style_feat_1)\n",
        "        beta = self.conv_beta(style_feat_1)\n",
        "\n",
        "        y = self.norm(x)\n",
        "        out_no_style = self.residual_dense_layers_no_style(y)\n",
        "        out_no_style = self.conv_1x1_b(out_no_style)\n",
        "        out_no_style = y + out_no_style\n",
        "        #out_no_style = self.noise(out_no_style, None)\n",
        "        out_no_style = self.norm2(out_no_style)\n",
        "        out_att = torch.sigmoid(self.conv_att(out_no_style))\n",
        "\n",
        "        out_new_style = self.adaIn(out_no_style, style_mean , style_std)\n",
        "        out_new_gamma = out_no_style * (1 + gamma) + beta\n",
        "        out_new = out_att * out_new_style + (1 - out_att) * out_new_gamma\n",
        "        out = self.conv_1x1_final(torch.cat([out, out_new], dim = 1))\n",
        "        out = self.ca(out)\n",
        "        out = out + x\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGWkkPElZpFK"
      },
      "source": [
        "class Generate_quarter(nn.Module):\n",
        "    def __init__(self, in_channels=3, depth_rate=16, kernel_size=3, stride=2, height=3, width=6, num_dense_layer=4, growth_rate=16, attention=True):\n",
        "        super(Generate_quarter, self).__init__()\n",
        "        self.rdb_module = nn.ModuleDict()\n",
        "        self.upsample_module = nn.ModuleDict()\n",
        "        self.downsample_module = nn.ModuleDict()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.stride = stride\n",
        "        self.depth_rate = depth_rate\n",
        "        self.coefficient = nn.Parameter(torch.Tensor(np.ones((height, width, 2, depth_rate*stride**(height-1)))), requires_grad=attention)\n",
        "        self.conv_in = nn.Conv2d(in_channels, depth_rate, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.conv_out = nn.Conv2d(depth_rate, in_channels, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.rdb_in = RDB(depth_rate, num_dense_layer, growth_rate)\n",
        "        self.rdb_out = RDB(depth_rate, num_dense_layer, growth_rate)\n",
        "\n",
        "        rdb_in_channels = depth_rate\n",
        "        for i in range(height):\n",
        "            for j in range(width - 1):\n",
        "                self.rdb_module.update({'{}_{}'.format(i, j): RDB(rdb_in_channels, num_dense_layer, growth_rate)})\n",
        "            rdb_in_channels *= stride\n",
        "\n",
        "        _in_channels = depth_rate\n",
        "        for i in range(height - 1):\n",
        "            for j in range(width // 2):\n",
        "                self.downsample_module.update({'{}_{}'.format(i, j): DownSample(_in_channels)})\n",
        "            _in_channels *= stride\n",
        "\n",
        "        for i in range(height - 2, -1, -1):\n",
        "            for j in range(width // 2, width):\n",
        "                self.upsample_module.update({'{}_{}'.format(i, j): UpSample(_in_channels)})\n",
        "            _in_channels //= stride\n",
        "\n",
        "        self.conv1 = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.conv2_atrous = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=2, dilation=2)\n",
        "        self.conv3_atrous = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=4, dilation=4)\n",
        "        self.conv4_atrous = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=8, dilation=8)\n",
        "        self.conv5_atrous = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=16, dilation=16)\n",
        "        self.conv6 = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.offset_conv1 = nn.Conv2d(depth_rate*4, depth_rate*2, 3, 1, 1, bias=True)\n",
        "        self.offset_conv2 = nn.Conv2d(depth_rate*2, depth_rate*4, 3, 1, 1, bias=True)\n",
        "        #self.dcnpack = DCN(depth_rate*4, depth_rate*4, 3, stride=1, padding=1, dilation=1, deformable_groups=8, extra_offset_mask=True)\n",
        "        self.upsamle1 = UpSample(depth_rate*4)\n",
        "        self.upsamle2 = UpSample(depth_rate*2)\n",
        "\n",
        "        self.rdb_2_1 = RDB(depth_rate * 2, num_dense_layer, growth_rate)\n",
        "        self.rdb_1_1 = RDB(depth_rate, num_dense_layer, growth_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp = self.conv_in(x)\n",
        "\n",
        "        x_index = [[0 for _ in range(self.width)] for _ in range(self.height)]\n",
        "        i, j = 0, 0\n",
        "\n",
        "        x_index[0][0] = self.rdb_in(inp)\n",
        "\n",
        "        for j in range(1, self.width // 2):\n",
        "            x_index[0][j] = self.rdb_module['{}_{}'.format(0, j-1)](x_index[0][j-1])\n",
        "\n",
        "        for i in range(1, self.height):\n",
        "            x_index[i][0] = self.downsample_module['{}_{}'.format(i-1, 0)](x_index[i-1][0])\n",
        "\n",
        "        for i in range(1, self.height):\n",
        "            for j in range(1, self.width // 2):\n",
        "                channel_num = int(2**(i-1)*self.stride*self.depth_rate)\n",
        "                x_index[i][j] = self.coefficient[i, j, 0, :channel_num][None, :, None, None] * self.rdb_module['{}_{}'.format(i, j-1)](x_index[i][j-1]) + \\\n",
        "                                self.coefficient[i, j, 1, :channel_num][None, :, None, None] * self.downsample_module['{}_{}'.format(i-1, j)](x_index[i-1][j])\n",
        "\n",
        "        x_index[i][j+1] = self.rdb_module['{}_{}'.format(i, j)](x_index[i][j])\n",
        "        k = j\n",
        "\n",
        "        for j in range(self.width // 2 + 1, self.width):\n",
        "            x_index[i][j] = self.rdb_module['{}_{}'.format(i, j-1)](x_index[i][j-1])\n",
        "\n",
        "        for i in range(self.height - 2, -1, -1):\n",
        "            channel_num = int(2 ** (i-1) * self.stride * self.depth_rate)\n",
        "            x_index[i][k+1] = self.coefficient[i, k+1, 0, :channel_num][None, :, None, None] * self.rdb_module['{}_{}'.format(i, k)](x_index[i][k]) + \\\n",
        "                              self.coefficient[i, k+1, 1, :channel_num][None, :, None, None] * self.upsample_module['{}_{}'.format(i, k+1)](x_index[i+1][k+1], x_index[i][k].size())\n",
        "\n",
        "        for i in range(self.height - 2, -1, -1):\n",
        "            for j in range(self.width // 2 + 1, self.width):\n",
        "                channel_num = int(2 ** (i - 1) * self.stride * self.depth_rate)\n",
        "                x_index[i][j] = self.coefficient[i, j, 0, :channel_num][None, :, None, None] * self.rdb_module['{}_{}'.format(i, j-1)](x_index[i][j-1]) + \\\n",
        "                                self.coefficient[i, j, 1, :channel_num][None, :, None, None] * self.upsample_module['{}_{}'.format(i, j)](x_index[i+1][j], x_index[i][j-1].size())\n",
        "\n",
        "        out = self.rdb_out(x_index[i][j])\n",
        "\n",
        "        feat_extra = F.relu(self.conv1(x_index[-1][j]))\n",
        "        feat_extra = F.relu(self.conv2_atrous(feat_extra))\n",
        "        feat_extra = F.relu(self.conv3_atrous(feat_extra))\n",
        "        feat_extra = F.relu(self.conv4_atrous(feat_extra))\n",
        "        feat_extra = F.relu(self.conv5_atrous(feat_extra))\n",
        "        feat_extra = F.relu(self.conv6(feat_extra))\n",
        "        offset = F.relu(self.offset_conv1(feat_extra))\n",
        "        offset = F.relu(self.offset_conv2(offset))\n",
        "        #feat_extra = F.relu(self.dcnpack([feat_extra, offset]))\n",
        "        feat_extra = self.upsamle1(feat_extra, x_index[-2][j].size())\n",
        "        feat_extra = self.coefficient[-2, 0, 0, :32][None, :, None, None] * x_index[-2][j] + self.coefficient[-2, 0, 0, 32:64][None, :, None, None] * feat_extra\n",
        "        feat_extra = self.rdb_2_1(feat_extra)\n",
        "        feat_extra = self.upsamle2(feat_extra, x_index[0][j].size())\n",
        "        feat_extra = self.coefficient[0, 0, 0, :16][None, :, None, None] * out + self.coefficient[0, 0, 0, 16:32][None, :, None, None] * feat_extra\n",
        "        out = self.rdb_1_1(feat_extra)\n",
        "        out = F.relu(self.conv_out(out))\n",
        "        #out = out + x\n",
        "        return out, feat_extra\n",
        "\n",
        "class Generate_quarter_refine(nn.Module):\n",
        "    def __init__(self, in_channels=3, depth_rate=16, kernel_size=3, stride=2, height=3, width=6, num_dense_layer=4, growth_rate=16, attention=True):\n",
        "        super(Generate_quarter_refine, self).__init__()\n",
        "        self.rdb_module = nn.ModuleDict()\n",
        "        self.upsample_module = nn.ModuleDict()\n",
        "        self.downsample_module = nn.ModuleDict()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.stride = stride\n",
        "        self.depth_rate = depth_rate\n",
        "        self.coefficient = nn.Parameter(torch.Tensor(np.ones((height, width, 2, depth_rate*stride**(height-1)))), requires_grad=attention)\n",
        "        self.conv_in = nn.Conv2d(in_channels, depth_rate, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.conv_out = nn.Conv2d(depth_rate, in_channels, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.rdb_in = RDB(depth_rate, num_dense_layer, growth_rate)\n",
        "        self.rdb_out = RDB(depth_rate, num_dense_layer, growth_rate)\n",
        "\n",
        "        rdb_in_channels = depth_rate\n",
        "        for i in range(height):\n",
        "            for j in range(width - 1):\n",
        "                self.rdb_module.update({'{}_{}'.format(i, j): RDB(rdb_in_channels, num_dense_layer, growth_rate)})\n",
        "            rdb_in_channels *= stride\n",
        "\n",
        "        _in_channels = depth_rate\n",
        "        for i in range(height - 1):\n",
        "            for j in range(width // 2):\n",
        "                self.downsample_module.update({'{}_{}'.format(i, j): DownSample(_in_channels)})\n",
        "            _in_channels *= stride\n",
        "\n",
        "        for i in range(height - 2, -1, -1):\n",
        "            for j in range(width // 2, width):\n",
        "                self.upsample_module.update({'{}_{}'.format(i, j): UpSample(_in_channels)})\n",
        "            _in_channels //= stride\n",
        "\n",
        "        self.conv1 = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.conv2_atrous = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=2, dilation=2)\n",
        "        self.conv3_atrous = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=4, dilation=4)\n",
        "        self.conv4_atrous = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=8, dilation=8)\n",
        "        self.conv5_atrous = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=16, dilation=16)\n",
        "        self.conv6 = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.offset_conv1 = nn.Conv2d(depth_rate*4, depth_rate*2, 3, 1, 1, bias=True)\n",
        "        self.offset_conv2 = nn.Conv2d(depth_rate*2, depth_rate*4, 3, 1, 1, bias=True)\n",
        "        #self.dcnpack = DCN(depth_rate*4, depth_rate*4, 3, stride=1, padding=1, dilation=1, deformable_groups=8, extra_offset_mask=True)\n",
        "        self.upsamle1 = UpSample(depth_rate*4)\n",
        "        self.upsamle2 = UpSample(depth_rate*2)\n",
        "\n",
        "        self.rdb_2_1 = RDB(depth_rate * 2, num_dense_layer, growth_rate)\n",
        "        self.rdb_1_1 = RDB(depth_rate, num_dense_layer, growth_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        inp = self.conv_in(x)\n",
        "\n",
        "        x_index = [[0 for _ in range(self.width)] for _ in range(self.height)]\n",
        "        i, j = 0, 0\n",
        "\n",
        "        x_index[0][0] = self.rdb_in(inp)\n",
        "\n",
        "        for j in range(1, self.width // 2):\n",
        "            x_index[0][j] = self.rdb_module['{}_{}'.format(0, j-1)](x_index[0][j-1])\n",
        "\n",
        "        for i in range(1, self.height):\n",
        "            x_index[i][0] = self.downsample_module['{}_{}'.format(i-1, 0)](x_index[i-1][0])\n",
        "\n",
        "        for i in range(1, self.height):\n",
        "            for j in range(1, self.width // 2):\n",
        "                channel_num = int(2**(i-1)*self.stride*self.depth_rate)\n",
        "                x_index[i][j] = self.coefficient[i, j, 0, :channel_num][None, :, None, None] * self.rdb_module['{}_{}'.format(i, j-1)](x_index[i][j-1]) + \\\n",
        "                                self.coefficient[i, j, 1, :channel_num][None, :, None, None] * self.downsample_module['{}_{}'.format(i-1, j)](x_index[i-1][j])\n",
        "\n",
        "        x_index[i][j+1] = self.rdb_module['{}_{}'.format(i, j)](x_index[i][j])\n",
        "        k = j\n",
        "\n",
        "        for j in range(self.width // 2 + 1, self.width):\n",
        "            x_index[i][j] = self.rdb_module['{}_{}'.format(i, j-1)](x_index[i][j-1])\n",
        "\n",
        "        for i in range(self.height - 2, -1, -1):\n",
        "            channel_num = int(2 ** (i-1) * self.stride * self.depth_rate)\n",
        "            x_index[i][k+1] = self.coefficient[i, k+1, 0, :channel_num][None, :, None, None] * self.rdb_module['{}_{}'.format(i, k)](x_index[i][k]) + \\\n",
        "                              self.coefficient[i, k+1, 1, :channel_num][None, :, None, None] * self.upsample_module['{}_{}'.format(i, k+1)](x_index[i+1][k+1], x_index[i][k].size())\n",
        "\n",
        "        for i in range(self.height - 2, -1, -1):\n",
        "            for j in range(self.width // 2 + 1, self.width):\n",
        "                channel_num = int(2 ** (i - 1) * self.stride * self.depth_rate)\n",
        "                x_index[i][j] = self.coefficient[i, j, 0, :channel_num][None, :, None, None] * self.rdb_module['{}_{}'.format(i, j-1)](x_index[i][j-1]) + \\\n",
        "                                self.coefficient[i, j, 1, :channel_num][None, :, None, None] * self.upsample_module['{}_{}'.format(i, j)](x_index[i+1][j], x_index[i][j-1].size())\n",
        "\n",
        "        out = self.rdb_out(x_index[i][j])\n",
        "        feat_extra = F.relu(self.conv1(x_index[-1][j]))\n",
        "        feat_extra = F.relu(self.conv2_atrous(feat_extra))\n",
        "        feat_extra = F.relu(self.conv3_atrous(feat_extra))\n",
        "        feat_extra = F.relu(self.conv4_atrous(feat_extra))\n",
        "        feat_extra = F.relu(self.conv5_atrous(feat_extra))\n",
        "        feat_extra = F.relu(self.conv6(feat_extra))\n",
        "        offset = F.relu(self.offset_conv1(feat_extra))\n",
        "        offset = F.relu(self.offset_conv2(offset))\n",
        "        #feat_extra = F.relu(self.dcnpack([feat_extra, offset]))\n",
        "        feat_extra = self.upsamle1(feat_extra, x_index[-2][j].size())\n",
        "        feat_extra = self.coefficient[-2, 0, 0, :32][None, :, None, None] * x_index[-2][j] + self.coefficient[-2, 0, 0, 32:64][None, :, None, None] * feat_extra\n",
        "        feat_extra = self.rdb_2_1(feat_extra)\n",
        "        feat_extra = self.upsamle2(feat_extra, x_index[0][j].size())\n",
        "        feat_extra = self.coefficient[0, 0, 0, :16][None, :, None, None] * out + self.coefficient[0, 0, 0, 16:32][None, :, None, None] * feat_extra\n",
        "        out = self.rdb_1_1(feat_extra)\n",
        "        feat = out\n",
        "        out = F.relu(self.conv_out(out))\n",
        "        #out = out + x\n",
        "        return out, feat, feat_extra\n",
        "\n",
        "class Generate(nn.Module):\n",
        "    def __init__(self, in_channels=3, depth_rate=16, kernel_size=3, stride=2, height=3, width=6, num_dense_layer=4, growth_rate=16, attention=True):\n",
        "        super(Generate, self).__init__()\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.stride = stride\n",
        "        self.depth_rate = depth_rate\n",
        "\n",
        "        self.conv_in_1 = nn.Conv2d(in_channels, depth_rate, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.conv_in_2 = nn.Conv2d(in_channels, depth_rate, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.conv_1_downsample = nn.Conv2d(depth_rate * 2, depth_rate * 2, kernel_size=kernel_size, padding=(kernel_size - 1) // 2, stride = 2)\n",
        "\n",
        "        self.conv_2 = nn.Conv2d(depth_rate * 2, depth_rate * 2, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.conv_2_downsample = nn.Conv2d(depth_rate * 2, depth_rate * 4, kernel_size=kernel_size, padding=(kernel_size - 1) // 2, stride = 2)\n",
        "\n",
        "        self.conv_3 = nn.Conv2d(depth_rate * 4, depth_rate * 4, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "        self.rdb_3_1 = RDB(depth_rate * 4, num_dense_layer, growth_rate)\n",
        "        self.rdb_3_2 = RDB(depth_rate * 4, num_dense_layer, growth_rate)\n",
        "\n",
        "        self.feat_pass = nn.Conv2d(depth_rate, depth_rate * 4, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "\n",
        "        self.rdb_3_3 = RDB(depth_rate * 4, num_dense_layer, growth_rate)\n",
        "        self.rdb_3_4 = RDB(depth_rate * 4, num_dense_layer, growth_rate)\n",
        "        self.rdb_3_5 = RDB(depth_rate * 4, num_dense_layer, growth_rate)\n",
        "        self.rdb_3_6 = RDB(depth_rate * 4, num_dense_layer, growth_rate)\n",
        "\n",
        "        self.conv_out = nn.Conv2d(depth_rate, in_channels, kernel_size=kernel_size, padding=(kernel_size - 1) // 2)\n",
        "\n",
        "        self.upsample_L3 = UpSample(depth_rate * 4)\n",
        "\n",
        "        self.rdb_2_1 = RDB(depth_rate * 2, num_dense_layer, growth_rate)\n",
        "        self.rdb_2_2 = RDB(depth_rate * 2, num_dense_layer, growth_rate)\n",
        "        self.rdb_2_3 = RDB(depth_rate * 2, num_dense_layer, growth_rate)\n",
        "        self.rdb_2_4 = RDB(depth_rate * 2, num_dense_layer, growth_rate)\n",
        "\n",
        "        self.upsample_L2 = UpSample(depth_rate * 2)\n",
        "\n",
        "        self.rdb_1_1 = RDB(depth_rate, num_dense_layer, growth_rate)\n",
        "        self.rdb_1_2 = RDB(depth_rate, num_dense_layer, growth_rate)\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2, feat):\n",
        "        inp1 = F.relu(self.conv_in_1(x1))\n",
        "        inp2 = F.relu(self.conv_in_2(x2))\n",
        "        conv2 = F.relu(self.conv_1_downsample(torch.cat([inp1, inp2], 1)))\n",
        "        conv2 = F.relu(self.conv_2(conv2))\n",
        "        conv3 = F.relu(self.conv_2_downsample(conv2))\n",
        "        conv3 = F.relu(self.conv_3(conv3))\n",
        "        conv3 = self.rdb_3_1(conv3)\n",
        "        conv3 = self.rdb_3_2(conv3)\n",
        "\n",
        "        # direct\n",
        "        feat_pass = self.feat_pass(feat)\n",
        "        conv3 = conv3 + feat_pass\n",
        "        conv3 = self.rdb_3_3(conv3)\n",
        "        conv3 = self.rdb_3_4(conv3)\n",
        "        conv3 = self.rdb_3_5(conv3)\n",
        "        conv3 = self.rdb_3_6(conv3)\n",
        "        conv2_up = self.upsample_L3(conv3, conv2.size())\n",
        "        conv2_up = self.rdb_2_1(conv2_up)\n",
        "        conv2_up = self.rdb_2_2(conv2_up)\n",
        "        conv2_up = self.rdb_2_3(conv2_up)\n",
        "        conv2_up = self.rdb_2_4(conv2_up)\n",
        "        conv1_up = self.upsample_L2(conv2_up, x1.size())\n",
        "        conv1_up = self.rdb_1_1(conv1_up)\n",
        "        conv1_up = self.rdb_1_2(conv1_up)\n",
        "        out = self.conv_out(conv1_up)\n",
        "        out = F.relu(out + x2)\n",
        "        return out\n",
        "\n",
        "class LossD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LossD, self).__init__()\n",
        "\n",
        "    def forward(self, r_x, r_x_hat):\n",
        "        return (F.relu(1 + r_x_hat) + F.relu(1 - r_x)).mean().reshape(1)\n",
        "\n",
        "class LossFeat(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LossFeat, self).__init__()\n",
        "\n",
        "    def forward(self, feats1, feats2):\n",
        "        loss = []\n",
        "        for (f1, f2) in zip(feats1, feats2):\n",
        "            loss.append(F.mse_loss(f1, f2))\n",
        "        return sum(loss)/len(loss)\n",
        "\n",
        "class Lap(nn.Module):\n",
        "    def __init__(self, channels=3):\n",
        "        super(Lap, self).__init__()\n",
        "        self.channels = channels\n",
        "        # print(\"channels: \", channels.shape)\n",
        "        kernel = [[0,1,0],[1,-4,1],[0,1,0]]#   [[1,1,1],[1,-8,1],[1,1,1]]\n",
        "\n",
        "        kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)    # (H, W) -> (1, 1, H, W)\n",
        "        kernel = kernel.expand((int(channels), 1, 3, 3))\n",
        "        self.weight = nn.Parameter(data=kernel, requires_grad=False).cuda()\n",
        "\n",
        "    def __call__(self, dehaze, gt):\n",
        "        #m = nn.Upsample(scale_factor=0.25, mode='nearest')\n",
        "        #gt = m(gt)\n",
        "        dehaze = F.conv2d(dehaze, self.weight, padding=1, groups=self.channels)\n",
        "        gt = F.conv2d(gt, self.weight, padding=1, groups=self.channels)\n",
        "        loss = []\n",
        "        for dehaze1, gt1 in zip(dehaze, gt):\n",
        "            loss.append(F.mse_loss(dehaze1, gt1))\n",
        "        return sum(loss)/len(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wMr2x2IPOAn"
      },
      "source": [
        "class Self_Attn(nn.Module):\n",
        "    \"\"\" Self attention Layer\"\"\"\n",
        "    def __init__(self,in_dim,activation,with_attn=False):\n",
        "        super(Self_Attn,self).__init__()\n",
        "        self.chanel_in = in_dim\n",
        "        self.activation = activation\n",
        "        self.with_attn = with_attn\n",
        "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
        "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
        "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "        self.softmax  = nn.Softmax(dim=-1) #\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "            inputs :\n",
        "                x : input feature maps( B X C X W X H)\n",
        "            returns :\n",
        "                out : self attention value + input feature\n",
        "                attention: B X N X N (N is Width*Height)\n",
        "        \"\"\"\n",
        "        m_batchsize,C,width ,height = x.size()\n",
        "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
        "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
        "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
        "        attention = self.softmax(energy) # BX (N) X (N)\n",
        "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
        "\n",
        "        out = torch.bmm(proj_value,attention.permute(0,2,1) )\n",
        "        out = out.view(m_batchsize,C,width,height)\n",
        "\n",
        "        out = self.gamma*out + x\n",
        "        if self.with_attn:\n",
        "            return out ,attention\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_nc, ndf=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.layer1_new = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(input_nc, ndf, 5, 2, 2)), nn.LeakyReLU(0.2, True)]) # 1/2\n",
        "        self.layer2 = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(ndf, ndf * 2, 5, 2, 2)), nn.LeakyReLU(0.2, True)]) # 1/4\n",
        "        self.layer3 = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(ndf * 2, ndf * 4, 5, 2, 2)), nn.LeakyReLU(0.2, True)]) # 1/8\n",
        "        self.layer4 = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(ndf * 4, ndf * 4, 5, 2, 2)), nn.LeakyReLU(0.2, True)]) # 1/16\n",
        "        self.layer5 = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(ndf * 4, ndf * 4, 5, 2, 2)), nn.LeakyReLU(0.2, True)]) # 1/32\n",
        "        self.att = Self_Attn(ndf * 4, 'relu')\n",
        "        self.layer6 = nn.Sequential(*[nn.utils.spectral_norm(nn.Conv2d(ndf * 4, ndf * 4, 5, 2, 2)), nn.LeakyReLU(0.2, True)]) # 1/64\n",
        "\n",
        "    def forward(self, input):\n",
        "        feats = []\n",
        "        out = self.layer1_new(input)\n",
        "        feats.append(out)\n",
        "        out = self.layer2(out)\n",
        "        feats.append(out)\n",
        "        out = self.layer3(out)\n",
        "        feats.append(out)\n",
        "        out = self.layer4(out)\n",
        "        feats.append(out)\n",
        "        out = self.layer5(out)\n",
        "        feats.append(out)\n",
        "        out = self.att(out)\n",
        "        out = self.layer6(out)\n",
        "        feats.append(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out, feats\n",
        "\n",
        "# --- Downsampling block in GridDehazeNet  --- #\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size=3, stride=2):\n",
        "        super(DownSample, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size, stride=stride, padding=(kernel_size-1)//2)\n",
        "        self.conv2 = nn.Conv2d(in_channels, stride*in_channels, kernel_size, stride=1, padding=(kernel_size - 1) // 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.relu(self.conv2(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "# --- Upsampling block in GridDehazeNet  --- #\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels, kernel_size=3, stride=2):\n",
        "        super(UpSample, self).__init__()\n",
        "        self.deconv = nn.ConvTranspose2d(in_channels, in_channels, kernel_size, stride=stride, padding=1)\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels // stride, kernel_size, stride=1, padding=(kernel_size - 1) // 2)\n",
        "\n",
        "    def forward(self, x, output_size):\n",
        "        out = F.relu(self.deconv(x, output_size=output_size))\n",
        "        out = F.relu(self.conv(out))\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEbqWh9aQf0Z"
      },
      "source": [
        "# --- Perceptual loss network  --- #\n",
        "class LossNetworkF(torch.nn.Module):\n",
        "    def __init__(self, vgg_model):\n",
        "        super(LossNetworkF, self).__init__()\n",
        "        self.vgg_layers = vgg_model\n",
        "        self.layer_name_mapping = {\n",
        "            '3': \"relu1_2\",\n",
        "            '8': \"relu2_2\",\n",
        "            '15': \"relu3_3\"\n",
        "        }\n",
        "\n",
        "    def output_features(self, x):\n",
        "        output = {}\n",
        "        for name, module in self.vgg_layers._modules.items():\n",
        "            x = module(x)\n",
        "            if name in self.layer_name_mapping:\n",
        "                output[self.layer_name_mapping[name]] = x\n",
        "        return list(output.values())\n",
        "\n",
        "    def forward(self, dehaze, gt):\n",
        "        loss = []\n",
        "        dehaze_features = self.output_features(dehaze)\n",
        "        gt_features = self.output_features(gt)\n",
        "        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):\n",
        "            size = dehaze_feature.size()\n",
        "            pad = torch.zeros(size).cuda()\n",
        "            print(size)\n",
        "            import ff\n",
        "            #dehaze_feature = torch.unsqueeze(dehaze_feature, 2)\n",
        "            dehaze_feature = torch.cat([dehaze_feature,pad], dim=2)\n",
        "            #gt_feature = torch.unsqueeze(gt_feature, 2)\n",
        "            gt_feature = torch.cat([gt_feature,pad], dim=2)\n",
        "            f1 = torch.fft(dehaze_feature, 2)\n",
        "            f2 = torch.fft(gt_feature, 2)\n",
        "            loss.append(F.mse_loss(f1[:,:,0]*f1[:,:,0]+f1[:,:,1]*f1[:,:,1], f2[:,:,0]*f2[:,:,0]+f2[:,:,1]*f2[:,:,1]))\n",
        "\n",
        "        return torch.from_numpy(sum(loss)/len(loss)).cuda()\n",
        "\n",
        "class LossNetwork(torch.nn.Module):\n",
        "    def __init__(self, vgg_model):\n",
        "        super(LossNetwork, self).__init__()\n",
        "        self.vgg_layers = vgg_model\n",
        "        self.layer_name_mapping = {\n",
        "            '3': \"relu1_2\",\n",
        "            '8': \"relu2_2\",\n",
        "            '15': \"relu3_3\"\n",
        "        }\n",
        "\n",
        "    def output_features(self, x):\n",
        "        output = {}\n",
        "        for name, module in self.vgg_layers._modules.items():\n",
        "            x = module(x)\n",
        "            if name in self.layer_name_mapping:\n",
        "                output[self.layer_name_mapping[name]] = x\n",
        "        return list(output.values())\n",
        "\n",
        "    def forward(self, dehaze, gt):\n",
        "        loss = []\n",
        "        dehaze_features = self.output_features(dehaze)\n",
        "        gt_features = self.output_features(gt)\n",
        "        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):\n",
        "            loss.append(F.mse_loss(dehaze_feature, gt_feature))\n",
        "\n",
        "        return sum(loss)/len(loss)\n",
        "\n",
        "class LossNetworkL1(torch.nn.Module):\n",
        "    def __init__(self, vgg_model):\n",
        "        super(LossNetworkL1, self).__init__()\n",
        "        self.vgg_layers = vgg_model\n",
        "        self.layer_name_mapping = {\n",
        "            '3': \"relu1_2\",\n",
        "            '8': \"relu2_2\",\n",
        "            '15': \"relu3_3\"\n",
        "        }\n",
        "        self.loss_rec = nn.L1Loss()\n",
        "\n",
        "    def output_features(self, x):\n",
        "        output = {}\n",
        "        for name, module in self.vgg_layers._modules.items():\n",
        "            x = module(x)\n",
        "            if name in self.layer_name_mapping:\n",
        "                output[self.layer_name_mapping[name]] = x\n",
        "        return list(output.values())\n",
        "\n",
        "    def forward(self, dehaze, gt):\n",
        "        loss = []\n",
        "        dehaze_features = self.output_features(dehaze)\n",
        "        gt_features = self.output_features(gt)\n",
        "        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):\n",
        "            loss.append(self.loss_rec(dehaze_feature, gt_feature))\n",
        "\n",
        "        return sum(loss)/len(loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJzSK5lvZsce"
      },
      "source": [
        "net = Generate_quarter(height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
        "net.apply(initialize_weights)\n",
        "print('First Phrase Init!')\n",
        "optimizer = torch.optim.Adam(list(net.parameters()), lr=learning_rate, betas=(0.5, 0.999))\n",
        "net = net.to(device)\n",
        "net = nn.DataParallel(net, device_ids=device_ids)\n",
        "pytorch_total_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "print(\"Total_params: {}\".format(pytorch_total_params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOsqOucWQE6S"
      },
      "source": [
        "# --- Define the perceptual loss network --- #\n",
        "vgg_model = vgg16(pretrained=True).features[:16]\n",
        "vgg_model = vgg_model.to(device)\n",
        "for param in vgg_model.parameters():\n",
        "    param.requires_grad = False\n",
        "loss_network = LossNetwork(vgg_model)\n",
        "loss_network.eval()\n",
        "loss_lap = Lap()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt7U4gJTQzaJ"
      },
      "source": [
        "start_epoch = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNWIrmtTSjzi"
      },
      "source": [
        "# --- Training dataset --- #\n",
        "class TrainData(data.Dataset):\n",
        "    def __init__(self, crop_size):\n",
        "        super().__init__()\n",
        "        train_csv = pd.read_csv('/content/drive/MyDrive/lg_vision/data/train.csv')\n",
        "        train_all_input_files = '/content/drive/MyDrive/lg_vision/data/train_input_img/'+train_csv['input_img']\n",
        "        train_label_all_input_files = '/content/drive/MyDrive/lg_vision/data/train_label_img/'+train_csv['label_img']\n",
        "        \n",
        "        #train 500 datasets\n",
        "        train_all_input_files = train_all_input_files[:480]\n",
        "        train_label_all_input_files = train_label_all_input_files[:480]\n",
        "        \n",
        "\n",
        "        haze_names = []\n",
        "        gt_names = []\n",
        "        for path in train_all_input_files:\n",
        "            haze_names.append(path)\n",
        "        \n",
        "        for path2 in train_label_all_input_files:\n",
        "            gt_names.append(path2)\n",
        "\n",
        "\n",
        "        self.haze_names = haze_names\n",
        "        self.gt_names = gt_names\n",
        "        self.crop_size = crop_size\n",
        " \n",
        "        self.haze_cache = {}\n",
        "        self.gt_cache = {}\n",
        "\n",
        "        for haze_name in haze_names:\n",
        "            if haze_name in self.haze_cache:\n",
        "                continue\n",
        "            haze_img = Image.open(haze_name).convert('RGB')\n",
        "            self.haze_cache[haze_name] = haze_img\n",
        "\n",
        "        for gt_name in gt_names:\n",
        "            if gt_name in self.gt_cache:\n",
        "                continue\n",
        "            gt_img = Image.open(gt_name).convert('RGB')\n",
        "            self.gt_cache[gt_name] = gt_img\n",
        "\n",
        "        print ('use cache')\n",
        "\n",
        "    def generate_scale_label(self, haze, gt):\n",
        "        f_scale = 0.8 + random.randint(0, 7) / 10.0\n",
        "        width, height = haze.size\n",
        "        haze = haze.resize((int(width * f_scale), (int(height * f_scale))), resample = (Image.BICUBIC))\n",
        "        gt = gt.resize((int(width * f_scale), (int(height * f_scale))), resample = (Image.BICUBIC))\n",
        "        return haze, gt\n",
        "\n",
        "    def get_images(self, index):\n",
        "        crop_width, crop_height = self.crop_size\n",
        "        haze_name = self.haze_names[index]\n",
        "        gt_name = self.gt_names[index]\n",
        "\n",
        "        haze_img = self.haze_cache[haze_name]\n",
        "        gt_img = self.gt_cache[gt_name]\n",
        "\n",
        "        haze_img, gt_img = self.generate_scale_label(haze_img, gt_img)\n",
        "        \n",
        "        width, height = haze_img.size\n",
        "\n",
        "        if width < crop_width or height < crop_height:\n",
        "            raise Exception('Bad image size: {}'.format(gt_name))\n",
        "\n",
        "        # --- x,y coordinate of left-top corner --- #\n",
        "        x, y = randrange(0, width - crop_width + 1), randrange(0, height - crop_height + 1)\n",
        "        haze_crop_img = haze_img.crop((x, y, x + crop_width, y + crop_height))\n",
        "        gt_crop_img = gt_img.crop((x, y, x + crop_width, y + crop_height))\n",
        "\n",
        "        rand_hor=random.randint(0,1)\n",
        "        rand_rot=random.randint(0,3)\n",
        "        haze_crop_img=tfs.RandomHorizontalFlip(rand_hor)(haze_crop_img)\n",
        "        gt_crop_img=tfs.RandomHorizontalFlip(rand_hor)(gt_crop_img)\n",
        "        if rand_rot:\n",
        "          haze_crop_img=FF.rotate(haze_crop_img,90*rand_rot)\n",
        "          gt_crop_img=FF.rotate(gt_crop_img,90*rand_rot)\n",
        "\n",
        "        # --- Transform to tensor --- #\n",
        "        transform_haze = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        transform_gt = Compose([ToTensor()])\n",
        "        haze = transform_haze(haze_crop_img)\n",
        "        gt = transform_gt(gt_crop_img)\n",
        "        haze_gt = transform_gt(gt_crop_img)\n",
        "\n",
        "        # --- Check the channel is 3 or not --- #\n",
        "        if list(haze.shape)[0] is not 3 or list(gt.shape)[0] is not 3:\n",
        "            raise Exception('Bad image channel: {}'.format(gt_name))\n",
        "\n",
        "        return haze, gt, haze_gt\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        res = self.get_images(index)\n",
        "        return res\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.haze_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXNB2xeBVFn7"
      },
      "source": [
        "# import pickle\n",
        "# file = open(\"/content/drive/MyDrive/lg_vision/train_data_\",'rb')\n",
        "# train_data = pickle.load(file)  \n",
        "\n",
        "train_data = TrainData(crop_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTk1o9fQOPl4"
      },
      "source": [
        "# import pickle\n",
        "# filehandler = open(\"/content/drive/MyDrive/lg_vision/train_data_480\",\"wb\")\n",
        "# pickle.dump(train_data,filehandler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3lpKHbLHt8P"
      },
      "source": [
        "\n",
        "# --- Validation/test dataset --- #\n",
        "class TestData(data.Dataset):\n",
        "    def __init__(self):\n",
        "        train_csv = pd.read_csv('/content/drive/MyDrive/lg_vision/data/train.csv')\n",
        "        train_all_input_files = '/content/drive/MyDrive/lg_vision/data/train_input_img/'+train_csv['input_img']\n",
        "        train_label_all_input_files = '/content/drive/MyDrive/lg_vision/data/train_label_img/'+train_csv['label_img']\n",
        "        \n",
        "        #train 122 datasets\n",
        "        train_all_input_files = train_all_input_files[480:]\n",
        "        train_label_all_input_files = train_label_all_input_files[480:]\n",
        "\n",
        "        \n",
        "        haze_names = []\n",
        "        gt_names = []\n",
        "\n",
        "        for path in train_all_input_files:\n",
        "            haze_names.append(path)\n",
        "        \n",
        "        for path2 in train_label_all_input_files:\n",
        "            gt_names.append(path2)\n",
        "\n",
        "        self.haze_names = haze_names\n",
        "        self.gt_names = gt_names\n",
        "        \n",
        "\n",
        "    def get_images(self, index):\n",
        "        haze_name = self.haze_names[index]\n",
        "        gt_name = self.gt_names[index]\n",
        "        haze_img = Image.open(haze_name)\n",
        "        gt_img = Image.open(gt_name)\n",
        "\n",
        "        # --- Transform to tensor --- #\n",
        "        transform_haze = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        #haze = transform_haze(haze_img)\n",
        "\n",
        "        transform_gt = Compose([ToTensor()])\n",
        "        gt = transform_gt(gt_img)\n",
        "        haze = transform_haze(haze_img)\n",
        "\n",
        "        return haze, gt, haze_name\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        res = self.get_images(index)\n",
        "        return res\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.haze_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sygpj5dKQIF"
      },
      "source": [
        "\n",
        "\n",
        "def main(test_phrase, test_epoch):\n",
        "    device_ids = [Id for Id in range(torch.cuda.device_count())]\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    test_batch_size = 1\n",
        "    network_height = 3\n",
        "    network_width = 6\n",
        "    num_dense_layer = 4\n",
        "    growth_rate = 16\n",
        "    test_phrase = test_phrase\n",
        "    crop_size = [1600, 1200]\n",
        "    test_data = TestData()\n",
        "    test_data_loader = DataLoader(test_data, batch_size=test_batch_size)\n",
        "\n",
        "    def save_image(dehaze, image_name, category):\n",
        "        #dehaze_images = torch.split(dehaze, 1, dim=0)\n",
        "        batch_num = len(dehaze)\n",
        "    \n",
        "        for ind in range(batch_num):\n",
        "          utils.save_image(dehaze[ind], '/content/drive/MyDrive/lg_vision/after/{}_results/{}'.format(category,image_name[ind].split('/')[-1][:-3]+'png'))\n",
        "\n",
        "    if test_phrase == 1:\n",
        "      G1 = Generate_quarter(height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
        "      G1 = G1.to(device)\n",
        "      G1 = nn.DataParallel(G1, device_ids=device_ids)\n",
        "      G1.load_state_dict(torch.load('/content/drive/MyDrive/lg_vision/checkpoint/1_'+str(test_epoch)+'.tar'))\n",
        "      G1.eval()\n",
        "      psnr=[]\n",
        "      net_time = 0.\n",
        "      net_count = 0.\n",
        "      for batch_id, test_data in enumerate(test_data_loader):\n",
        "          with torch.no_grad():\n",
        "              haze, gt, image_name = test_data\n",
        "              #haze = F.interpolate(haze, scale_factor = 0.25)\n",
        "              haze = haze.to(device)\n",
        "              gt = gt.to(device)\n",
        "              start_time = time.time()\n",
        "              dehaze, _ = G1(haze)\n",
        "              end_time = time.time() - start_time\n",
        "              net_time += end_time\n",
        "              net_count += 1\n",
        "              test_info = to_psnr_test(dehaze, gt)\n",
        "              psnr.append(sum(test_info) / len(test_info))\n",
        "              print (\"test : \",sum(test_info) / len(test_info))\n",
        "      # --- Save image --- #\n",
        "          save_image(dehaze,image_name,\"NH\")\n",
        "      test_psnr = sum(psnr) / len(psnr)\n",
        "      print ('Test PSNR:' + str(test_psnr))\n",
        "      print('net time is {0:.4f}'.format(net_time / net_count))\n",
        "\n",
        "    # if test_phrase == 2:\n",
        "    #     G1 = Generate_quarter(height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
        "    #     G1 = G1.to(device)\n",
        "    #     G1 = nn.DataParallel(G1, device_ids=device_ids)\n",
        "    #     #G1.load_state_dict(torch.load('./checkpoint/1.tar'))\n",
        "    #     G2 = Generate_quarter_refine(height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
        "    #     G2 = G2.to(device)\n",
        "    #     G2 = nn.DataParallel(G2, device_ids=device_ids)\n",
        "    #     G1.load_state_dict(torch.load('./checkpoint/2-'+str(test_epoch)+'_G1.tar'))\n",
        "\n",
        "    #     G2.load_state_dict(torch.load('./checkpoint/2_' + str(test_epoch) +'_G2.tar'))\n",
        "    #     G1.eval()\n",
        "    #     G2.eval()\n",
        "    #     psnr=[]\n",
        "    #     net_time = 0.\n",
        "    #     net_count = 0.\n",
        "    #     for batch_id, test_data in enumerate(test_data_loader):\n",
        "    #         with torch.no_grad():\n",
        "    #             haze, gt, image_name = test_data\n",
        "    #             #haze = F.interpolate(haze, scale_factor = 0.25,recompute_scale_factor=True)\n",
        "    #             haze = haze.to(device)\n",
        "    #             gt =gt.to(device)\n",
        "    #             start_time = time.time()\n",
        "    #             dehaze_1, feat1 = G1(haze)\n",
        "    #             dehaze, _, _ = G2(dehaze_1)\n",
        "    #             gt = gt\n",
        "    #             end_time = time.time() - start_time\n",
        "    #             net_time += end_time\n",
        "    #             net_count += 1\n",
        "    #             test_info = to_psnr_test(dehaze, gt)\n",
        "    #             psnr.append(sum(test_info) / len(test_info))\n",
        "    #             print (sum(test_info) / len(test_info))\n",
        "    #         # --- Save image --- #\n",
        "    #         save_image(dehaze, image_name, 'NH')\n",
        "    #     test_psnr = sum(psnr) / len(psnr)\n",
        "    #     print ('Test PSNR:' + str(test_psnr))\n",
        "    #     print('net time is {0:.4f}'.format(net_time / net_count))\n",
        "\n",
        "    # if test_phrase == 3:\n",
        "    #     G1 = Generate_quarter(height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
        "    #     G1 = G1.to(device)\n",
        "    #     G1 = nn.DataParallel(G1, device_ids=device_ids)\n",
        "    #     G1.load_state_dict(torch.load('./checkpoint/3-'+str(test_epoch)+'_G1.tar'))\n",
        "    #     G2 = Generate_quarter_refine(height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
        "    #     G2 = G2.to(device)\n",
        "    #     G2 = nn.DataParallel(G2, device_ids=device_ids)\n",
        "    #     G2.load_state_dict(torch.load('./checkpoint/3_'+str(test_epoch)+'_G2.tar'))\n",
        "    #     G3 = Generate(height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
        "    #     G3 = G3.to(device)\n",
        "    #     G3 = nn.DataParallel(G3, device_ids=device_ids)\n",
        "    #     G3.load_state_dict(torch.load('./checkpoint/33_'+str(test_epoch)+'_G3.tar'))\n",
        "    #     G1.eval()\n",
        "    #     G2.eval()\n",
        "    #     G3.eval()\n",
        "    #     psnr=[]\n",
        "    #     net_time = 0.\n",
        "    #     net_count = 0.\n",
        "    #     for batch_id, test_data in enumerate(test_data_loader):\n",
        "    #         with torch.no_grad():\n",
        "    #             haze, gt, image_name = test_data\n",
        "    #             haze = haze.to(device)\n",
        "    #             gt = gt.to(device)\n",
        "    #             start_time = time.time()\n",
        "    #             dehaze_1, feat1 = G1(F.interpolate(haze, scale_factor = 0.25,recompute_scale_factor=True))\n",
        "    #             dehaze_2, feat, feat2 = G2(dehaze_1)\n",
        "    #             dehaze= G3(haze, F.interpolate(dehaze_2, scale_factor = 4,recompute_scale_factor=True), feat)\n",
        "    #             end_time = time.time() - start_time\n",
        "    #             net_time += end_time\n",
        "    #             net_count += 1\n",
        "    #             test_info = to_psnr(dehaze, gt)\n",
        "    #             psnr.append(sum(test_info) / len(test_info))\n",
        "    #             print (sum(test_info) / len(test_info))\n",
        "    #         # --- Save image --- #\n",
        "    #         save_image(dehaze, image_name, 'NH')\n",
        "    #     test_psnr = sum(psnr) / len(psnr)\n",
        "    #     print ('Test PSNR:' + str(test_psnr))\n",
        "    #     print('net time is {0:.4f}'.format(net_time / net_count))\n",
        "    return test_psnr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW8TKUPG6BKf"
      },
      "source": [
        "if device.type == 'cuda':\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM24bL77X250"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exsg650GwV0i"
      },
      "source": [
        "train_data_loader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True, num_workers = 2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hdMUA6n4kyT"
      },
      "source": [
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NH1vYM_wPtK"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as utils\n",
        "from math import log10\n",
        "from skimage import measure\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def to_psnr(dehaze, gt):\n",
        "    mse = F.mse_loss(dehaze, gt, reduction='none')\n",
        "    mse_split = torch.split(mse, 1, dim=0)\n",
        "    mse_list = [torch.mean(torch.squeeze(mse_split[ind])).item() for ind in range(len(mse_split))]\n",
        "\n",
        "    intensity_max = 1.0\n",
        "    psnr_list = [10.0 * log10(intensity_max / mse) for mse in mse_list]\n",
        "    return psnr_list\n",
        "\n",
        "def to_psnr_test(dehaze, gt):\n",
        "    #print(dehaze.size())\n",
        "    #print(gt.size())\n",
        "    #m = nn.Upsample(scale_factor=4)\n",
        "    #dehaze = m(dehaze)\n",
        "    #print(dehaze.size())\n",
        "    #import ff\n",
        "    mse = F.mse_loss(dehaze, gt, reduction='none')\n",
        "    mse_split = torch.split(mse, 1, dim=0)\n",
        "    mse_list = [torch.mean(torch.squeeze(mse_split[ind])).item() for ind in range(len(mse_split))]\n",
        "\n",
        "    intensity_max = 1.0\n",
        "    psnr_list = [10.0 * log10(intensity_max / mse) for mse in mse_list]\n",
        "    return psnr_list\n",
        "\n",
        "\n",
        "def to_ssim_skimage(dehaze, gt):\n",
        "    dehaze_list = torch.split(dehaze, 1, dim=0)\n",
        "    gt_list = torch.split(gt, 1, dim=0)\n",
        "\n",
        "    dehaze_list_np = [dehaze_list[ind].permute(0, 2, 3, 1).data.cpu().numpy().squeeze() for ind in range(len(dehaze_list))]\n",
        "    gt_list_np = [gt_list[ind].permute(0, 2, 3, 1).data.cpu().numpy().squeeze() for ind in range(len(dehaze_list))]\n",
        "    ssim_list = [measure.compare_ssim(dehaze_list_np[ind],  gt_list_np[ind], data_range=1, multichannel=True) for ind in range(len(dehaze_list))]\n",
        "\n",
        "    return ssim_list\n",
        "\n",
        "\n",
        "def validation(net, val_data_loader, device, category, save_tag=False):\n",
        "    \"\"\"\n",
        "    :param net: GateDehazeNet\n",
        "    :param val_data_loader: validation loader\n",
        "    :param device: The GPU that loads the network\n",
        "    :param category: indoor or outdoor test dataset\n",
        "    :param save_tag: tag of saving image or not\n",
        "    :return: average PSNR value\n",
        "    \"\"\"\n",
        "    psnr_list = []\n",
        "    ssim_list = []\n",
        "\n",
        "    for batch_id, val_data in enumerate(val_data_loader):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            haze, gt, image_name = val_data\n",
        "            haze = haze.to(device)\n",
        "            gt = gt.to(device)\n",
        "            dehaze = net(haze)\n",
        "\n",
        "        # --- Calculate the average PSNR --- #\n",
        "        psnr_list.extend(to_psnr(dehaze, gt))\n",
        "\n",
        "        # --- Calculate the average SSIM --- #\n",
        "        ssim_list.extend(to_ssim_skimage(dehaze, gt))\n",
        "\n",
        "        # --- Save image --- #\n",
        "        if save_tag:\n",
        "            save_image(dehaze, image_name, category)\n",
        "\n",
        "    avr_psnr = sum(psnr_list) / len(psnr_list)\n",
        "    avr_ssim = sum(ssim_list) / len(ssim_list)\n",
        "    return avr_psnr, avr_ssim\n",
        "\n",
        "def test_net(G2, G1, G3, test_data_loader, device, save_tag=False):\n",
        "    net_time = 0.\n",
        "    net_count = 0.\n",
        "    for batch_id, test_data in enumerate(test_data_loader):\n",
        "        with torch.no_grad():\n",
        "            haze, image_name = test_data\n",
        "            haze = haze.to(device)\n",
        "            start_time = time.time()\n",
        "            dehaze_1, feat1 = G1(F.interpolate(haze, scale_factor = 0.25))\n",
        "            dehaze_2, feat, feat2 = G2(dehaze_1)\n",
        "            dehaze, _, _ = G3(haze, F.interpolate(dehaze_2, scale_factor = 4), feat, feat1, feat2)\n",
        "            end_time = time.time() - start_time\n",
        "            net_time += end_time\n",
        "            net_count += 1\n",
        "\n",
        "        # --- Save image --- #\n",
        "        if save_tag:\n",
        "            save_image(dehaze, image_name, 'NH')\n",
        "\n",
        "    print('net time is {0:.4f}'.format(net_time / net_count))\n",
        "\n",
        "def save_image(dehaze, image_name, category):\n",
        "    dehaze_images = torch.split(dehaze, 1, dim=0)\n",
        "    batch_num = len(dehaze_images)\n",
        "\n",
        "    for ind in range(batch_num):\n",
        "        utils.save_image(dehaze_images[ind], '{}_results/{}'.format(category, image_name[ind][:-3] + 'png'))\n",
        "\n",
        "\n",
        "def print_log(epoch, train_psnr, category):\n",
        "    # --- Write the training log --- #\n",
        "    \n",
        "    with open('/content/drive/MyDrive/lg_vision/training_log/{}_log.txt'.format(category), 'a') as f:\n",
        "        print('Date: {0}s, Time_Cost: {1:.0f}s, Epoch: [{2}/{3}], Train_PSNR: {4:.2f}, Val_PSNR: {5:.2f}, Val_SSIM: {6:.4f}'\n",
        "              .format(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime()),\n",
        "                      0, epoch, 0, train_psnr, 0, 0), file=f)\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, category, lr_decay=0.5):\n",
        "\n",
        "    # --- Decay learning rate --- #\n",
        "    # step = 20 if category == 'indoor' else 2000\n",
        "\n",
        "    step = 200\n",
        "    if not epoch % step and epoch > 0:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] *= lr_decay\n",
        "            print('Learning rate sets to {}.'.format(param_group['lr']))\n",
        "    else:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            print('Learning rate sets to {}.'.format(param_group['lr']))\n",
        "\n",
        "def positiivate_weights(x):\n",
        "    return F.relu(x) / (F.relu(x) + 1e-10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8wR1ME4RMnD"
      },
      "source": [
        "loss_rec1 = nn.SmoothL1Loss()\n",
        "loss_rec2 = nn.MSELoss()\n",
        "num = 0\n",
        "train_phrase =1\n",
        "avg = nn.AvgPool2d(3, stride = 2, padding = 1)\n",
        "num_epochs = 500\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    psnr_list = []\n",
        "    start_time = time.time()\n",
        "    adjust_learning_rate(optimizer, epoch, category=category)\n",
        "\n",
        "    for batch_id, train_data in enumerate(train_data_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        haze, gt, haze_gt = train_data\n",
        "        haze = haze.to(device)\n",
        "        gt = gt.to(device)\n",
        "        haze_gt = haze_gt.to(device)\n",
        "        gt_quarter_1 = F.interpolate(gt, scale_factor = 0.25,recompute_scale_factor=True)\n",
        "        gt_quarter_2 = F.interpolate(gt, scale_factor = 0.25,recompute_scale_factor=True)\n",
        "\n",
        "        # --- Forward + Backward + Optimize --- #\n",
        "\n",
        "        # if train_phrase == 1:\n",
        "        dehaze_1, feat_extra_1 = net(haze)\n",
        "        rec_loss1 = loss_rec1(dehaze_1, gt)\n",
        "        perceptual_loss = loss_network(dehaze_1, gt)\n",
        "        lap_loss = loss_lap(dehaze_1, gt)\n",
        "        psnr = to_psnr(dehaze_1, gt)\n",
        "        psnr_list.extend(to_psnr(dehaze_1, gt))\n",
        "        train_info = to_psnr(dehaze_1, gt)\n",
        "        # if train_phrase == 2:\n",
        "        #     dehaze_1, feat_extra_1 = net(haze)\n",
        "        #     dehaze_2, feat, feat_extra_2 = G2(dehaze_1)\n",
        "        #     rec_loss1 = (loss_rec1(dehaze_2, gt) + loss_rec1(dehaze_1, gt))/2.0\n",
        "        #     rec_loss2 = loss_rec2(dehaze_2, gt)\n",
        "        #     perceptual_loss = loss_network(dehaze_2, gt)\n",
        "        #     lap_loss = loss_lap(dehaze_2, gt)\n",
        "        #     psnr = to_psnr(dehaze_2, gt)\n",
        "        #     psnr_list.extend(to_psnr(dehaze_2, gt))\n",
        "        #     train_info = to_psnr(dehaze_2, gt)\n",
        "        # if train_phrase == 3:\n",
        "        #     dehaze_1, feat_extra_1 = net(F.interpolate(haze, scale_factor = 0.25,recompute_scale_factor=True))\n",
        "        #     dehaze_2, feat, feat_extra_2 = G2(dehaze_1)\n",
        "        #     dehaze = G3(haze, F.interpolate(dehaze_2, scale_factor = 4,recompute_scale_factor=True), feat)\n",
        "        #     rec_loss1 = (loss_rec1(dehaze, gt) + loss_rec1(dehaze_2, gt_quarter_2)+loss_rec1(dehaze_1, gt_quarter_1))/3.0\n",
        "        #     rec_loss2 = loss_rec2(dehaze, gt)\n",
        "        #     perceptual_loss = (loss_network(dehaze, gt) + loss_network(F.interpolate(dehaze, scale_factor = 0.5,recompute_scale_factor=True), F.interpolate(gt, scale_factor = 0.5,recompute_scale_factor=True)) + loss_network(F.interpolate(dehaze, scale_factor = 0.25,recompute_scale_factor=True), F.interpolate(gt, scale_factor = 0.25,recompute_scale_factor=True)) + loss_network(dehaze_2, gt_quarter_2))/4.0\n",
        "        #     lap_loss = loss_lap(dehaze, gt)\n",
        "        #     psnr = to_psnr(dehaze, gt)\n",
        "        #     psnr_list.extend(to_psnr(dehaze, gt))\n",
        "        #     train_info = to_psnr(dehaze, gt)\n",
        "\n",
        "        loss = (rec_loss1) * 1.2 + 0.04 *perceptual_loss #+ 0.5 * lap_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if not (batch_id % 1):\n",
        "            print('Epoch: {0}, Iteration: {1}'.format(epoch, batch_id))\n",
        "            print (sum(train_info) / len(train_info))\n",
        "            writer.add_scalar('scalar/loss_w/ IN', loss, num)\n",
        "            writer.add_scalar('scalar/psnr_w/ IN', sum(psnr) / len(psnr), num)\n",
        "            num = num + 1\n",
        "\n",
        "    # --- Calculate the average training PSNR in one epoch --- #\n",
        "    train_psnr = sum(psnr_list) / len(psnr_list)\n",
        "    print_log(epoch+1, train_psnr, category)\n",
        "\n",
        "    if epoch % 5==0:\n",
        "        torch.save(net.state_dict(), '/content/drive/MyDrive/lg_vision/checkpoint/'+str(int(train_phrase))+'_'+str(epoch)+'.tar')\n",
        "        # if train_phrase == 2:\n",
        "        #     torch.save(net.state_dict(),'./checkpoint/'+str(int(train_phrase))+'-'+str(int(epoch))+'_G1.tar')\n",
        "        #     torch.save(G2.state_dict(), './checkpoint/'+str(int(train_phrase))+'_'+str(int(epoch))+'_G2.tar')\n",
        "        # if train_phrase == 3:\n",
        "        #     torch.save(net.state_dict(),'./checkpoint/'+str(int(train_phrase))+'-'+str(int(epoch))+'_G1.tar')\n",
        "        #     torch.save(G2.state_dict(), './checkpoint/'+str(int(train_phrase))+'_'+str(int(epoch))+'_G2.tar')\n",
        "        #     torch.save(G3.state_dict(), './checkpoint/'+str(int(train_phrase))+str(int(train_phrase))+'_'+str(epoch)+'_G3.tar')\n",
        "        test_psnr = main(1, epoch)\n",
        "        writer.add_scalar('scalar/psnr_test_w/ IN', test_psnr, epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLs0aIZZ6Nr6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgd5rR1sBdkX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q406F4x_46Xh"
      },
      "source": [
        "Result\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEMRM2yV5vQv"
      },
      "source": [
        "\n",
        "# --- Validation/test dataset --- #\n",
        "class SubmissionData(data.Dataset):\n",
        "    def __init__(self):\n",
        "        test_csv = pd.read_csv('/content/drive/MyDrive/lg_vision/data/test.csv')\n",
        "        test_all_input_files = '/content/drive/MyDrive/lg_vision/data/test_input_img/'+test_csv['input_img']\n",
        "        test_submission_files = '/content/drive/MyDrive/lg_vision/data/test_input_img/'+test_csv['submission_name']\n",
        "        \n",
        "\n",
        "        \n",
        "        input_names = []\n",
        "        submission_names = []\n",
        "\n",
        "        for path in test_all_input_files:\n",
        "            input_names.append(path)\n",
        "        \n",
        "        for path2 in test_submission_files:\n",
        "            submission_names.append(path2)\n",
        "\n",
        "        self.input_names = input_names\n",
        "        self.submission_names = submission_names\n",
        "      \n",
        "\n",
        "    def get_images(self, index):\n",
        "        input_name = self.input_names[index]\n",
        "        input_img = Image.open(input_name)\n",
        "\n",
        "        # --- Transform to tensor --- #\n",
        "        transform_input = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        #haze = transform_haze(haze_img)\n",
        "\n",
        "        input = transform_input(input_img)\n",
        "\n",
        "        return input, input_name\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        res = self.get_images(index)\n",
        "        return res\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KYVPtwgZz35"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "test_batch_size = 1\n",
        "network_height = 3\n",
        "network_width = 6\n",
        "num_dense_layer = 4\n",
        "growth_rate = 16\n",
        "test_phrase = 1\n",
        "\n",
        "\n",
        "crop_size = [1600, 1200]\n",
        "test_data = SubmissionData()\n",
        "test_data_loader = DataLoader(test_data, batch_size=test_batch_size)\n",
        "\n",
        "test_epoch = 495\n",
        "\n",
        "def save_image(dehaze, image_name):\n",
        "    #dehaze_images = torch.split(dehaze, 1, dim=0)\n",
        "    batch_num = len(dehaze)\n",
        "\n",
        "    for ind in range(batch_num):\n",
        "      utils.save_image(dehaze[ind], '/content/drive/MyDrive/lg_vision/submission/{}'.format(image_name[ind].split('/')[-1][:-3]+'png'))\n",
        "\n",
        "\n",
        "if test_phrase == 1:\n",
        "  G1 = Generate_quarter(height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
        "  G1 = G1.to(device)\n",
        "  G1 = nn.DataParallel(G1, device_ids=device_ids)\n",
        "  G1.load_state_dict(torch.load('/content/drive/MyDrive/lg_vision/checkpoint/1_'+str(test_epoch)+'.tar'))\n",
        "  G1.eval()\n",
        "\n",
        "  for batch_id, test_data in enumerate(test_data_loader):\n",
        "      with torch.no_grad():\n",
        "          haze, image_name = test_data\n",
        "          #haze = F.interpolate(haze, scale_factor = 0.25)\n",
        "          haze = haze.to(device)\n",
        "          dehaze, _ = G1(haze)\n",
        "  \n",
        "          \n",
        "  # --- Save image --- #\n",
        "      save_image(dehaze,image_name)\n",
        "\n",
        "  print('success')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waj1e8ThDrdC"
      },
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "device_ids = [Id for Id in range(torch.cuda.device_count())]\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = 'cpu'\n",
        "\n",
        "test_batch_size = 1\n",
        "network_height = 3\n",
        "network_width = 6\n",
        "num_dense_layer = 4\n",
        "growth_rate = 16\n",
        "test_phrase = 1\n",
        "\n",
        "\n",
        "crop_size = [1600, 1200]\n",
        "test_data = SubmissionData()\n",
        "test_data_loader = DataLoader(test_data, batch_size=test_batch_size, num_workers =2)\n",
        "\n",
        "test_epoch = 495\n",
        "\n",
        "def save_image(dehaze, image_name):\n",
        "    #dehaze_images = torch.split(dehaze, 1, dim=0)\n",
        "    batch_num = len(dehaze)\n",
        "\n",
        "    for ind in range(batch_num):\n",
        "      utils.save_image(dehaze[ind], '/content/drive/MyDrive/lg_vision/submission/{}'.format(image_name[ind].split('/')[-1][:-3]+'png'))\n",
        "\n",
        "with torch.no_grad():\n",
        "  if test_phrase == 1:\n",
        "    G1 = Generate_quarter(height=network_height, width=network_width, num_dense_layer=num_dense_layer, growth_rate=growth_rate)\n",
        "    G1 = G1.to(device)\n",
        "    G1 = nn.DataParallel(G1, device_ids=device_ids)\n",
        "    G1.load_state_dict(torch.load('/content/drive/MyDrive/lg_vision/checkpoint/1_'+str(test_epoch)+'.tar'))\n",
        "    G1.eval()\n",
        "\n",
        "    for batch_id, test_data in enumerate(test_data_loader):\n",
        "      haze, image_name = test_data\n",
        "      haze = haze.to(device)\n",
        "      print(haze)\n",
        "      dehaze, _ = G1(haze)\n",
        "      save_image(dehaze,image_name)\n",
        "    print('success')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRZewjb_MWbk"
      },
      "source": [
        "torch.cuda.get_device_properties(device).total_memory\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_jRgvq9IAnc"
      },
      "source": [
        "torch.cuda.memory_allocated()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_wLwO96ErLj"
      },
      "source": [
        "st ='/content/drive/MyDrive/lg_vision/data/train_input_img/train_input_10500.png'\n",
        "print(st.split('/')[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF5k20YSSuCZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYQSwQ0O2dlO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}